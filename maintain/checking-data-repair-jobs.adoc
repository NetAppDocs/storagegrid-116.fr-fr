---
permalink: maintain/checking-data-repair-jobs.html 
sidebar: sidebar 
keywords: storagegrid, data repair 
summary: 'Avant de mettre un nœud de grille hors service, vous devez confirmer qu"aucun travail de réparation de données n"est actif. Si des réparations ont échoué, vous devez les redémarrer et leur permettre d"effectuer la procédure de mise hors service.' 
---
= Vérifier les travaux de réparation des données
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Avant de mettre un nœud de grille hors service, vous devez confirmer qu'aucun travail de réparation de données n'est actif. Si des réparations ont échoué, vous devez les redémarrer et leur permettre d'effectuer la procédure de mise hors service.

Si vous devez désaffecter un nœud de stockage déconnecté, vous devez également effectuer ces étapes une fois la procédure de mise hors service terminée afin de vous assurer que la tâche de réparation des données a bien été effectuée. Vous devez vous assurer que tous les fragments avec code d'effacement qui se trouvaient sur le nœud supprimé ont été restaurés correctement.

Ces étapes s'appliquent uniquement aux systèmes dotés d'objets avec code d'effacement.

. Connectez-vous au nœud d'administration principal :
+
.. Saisissez la commande suivante : `ssh admin@_grid_node_IP_`
+
Lorsque vous êtes connecté en tant que root, l'invite passe de `$` à `#`.

.. Entrez le mot de passe indiqué dans le `Passwords.txt` fichier.
.. Entrez la commande suivante pour passer à la racine : `su -`
.. Entrez le mot de passe indiqué dans le `Passwords.txt` fichier.


. Vérifier l'exécution des réparations : `repair-data show-ec-repair-status`
+
** Si vous n'avez jamais exécuté de tâche de réparation de données, la sortie est `No job found`. Il n'est pas nécessaire de redémarrer les travaux de réparation.
** Si la tâche de réparation de données a été exécutée précédemment ou est en cours d'exécution, la sortie répertorie les informations relatives à la réparation. Chaque réparation possède un ID de réparation unique. Passez à l'étape suivante.


+
[listing]
----
root@DC1-ADM1:~ # repair-data show-ec-repair-status

Repair ID Scope Start Time End Time State Est/Affected Bytes Repaired Retry Repair
===================================================================================
949283 DC1-S-99-10(Volumes: 1,2) 2016-11-30T15:27:06.9 Success 17359 17359 No
949292 DC1-S-99-10(Volumes: 1,2) 2016-11-30T15:37:06.9 Failure 17359 0     Yes
949294 DC1-S-99-10(Volumes: 1,2) 2016-11-30T15:47:06.9 Failure 17359 0     Yes
949299 DC1-S-99-10(Volumes: 1,2) 2016-11-30T15:57:06.9 Failure 17359 0     Yes
----
. Si l'état pour toutes les réparations est `Success`, il n'est pas nécessaire de redémarrer les travaux de réparation.
. Si l'état pour une réparation est `Failure`, vous devez redémarrer cette réparation.
+
.. Obtenir l'ID de réparation pour la réparation ayant échoué à partir du résultat.
.. Exécutez le `repair-data start-ec-node-repair` commande.
+
Utilisez le `--repair-id` Pour spécifier l'ID de réparation. Par exemple, si vous souhaitez réessayer une réparation avec l'ID de réparation 949292, exécutez la commande suivante : `repair-data start-ec-node-repair --repair-id 949292`

.. Continuer à suivre l'état des réparations de données EC jusqu'à ce que l'état pour toutes les réparations soit `Success`.



